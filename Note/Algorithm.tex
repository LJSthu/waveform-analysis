\section{Algorithm} % (fold)

Before taking deep look into the methods, input and output need to be defined. The input is pedestal subtracted PMT waveform (see figure~\ref{fig:input}), and the output is the $q_{r}$ or $n_{r}$ sequence (see figure~\ref{fig:output}). 

\begin{minipage}{.5\textwidth}
\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/wave.pgf}}
    \caption{\label{fig:input} Data Input}
\end{figure}
\end{minipage}
\begin{minipage}{.5\textwidth}
\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/charge.pgf}}
    \caption{\label{fig:output} Data Output}
\end{figure}
\end{minipage}

The histogram of $N_{pe}$ and data structure show in figure (see figure~\ref{fig:penum}). 

\begin{minipage}{.51\textwidth}
\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/penum.pgf}}
    \caption{\label{fig:penum} $N_{pe}$ Histogram}
\end{figure}
\end{minipage}
\begin{minipage}{.49\textwidth}
\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/dataframe.pgf}}
    \caption{\label{fig:set} Data Structure}
\end{figure}
\end{minipage}

\subsection{Find peak}
First intuitive method is find peak method. We first smooth the input waveform using Savitzkyâ€“Golay filter, find the peak of waveform, then move the peaks leftward. The $\Delta t$ we move is the peak time of $v_{spe}$. The demonstration here shows a result with W-dist = 11.29ns. 

\begin{figure}[H]
    \centering
    \scalebox{0.4}{\input{figures/findpeak.pgf}}
    \caption{Find Peak Method Demo, W-dist = 11.29ns}
\end{figure}

\subsection{Waveform shift}
A threshold $v_{th}$ is settled with respect to noise in simulation data. In waveform shift method, first we locate $v_{w}(t)$ which exceeds $v_{th}$. Then we shift the exceeding part leftward. The $\Delta t$ we move is the peak time of $v_{spe}$. And treat the normalized exceeding part as $q_{r}(t_{H})$ or $n_{r}(t_{H})$. The demonstration here shows a result with W-dist = 10.75ns. 

\begin{figure}[H]
    \centering
    \scalebox{0.4}{\input{figures/threshold.pgf}}
    \caption{Waveform Shift Method Demo, W-dist = 10.75ns}
\end{figure}

\subsection{Fourier transform deconvolution}
Third method is Fourier deconvolution. First we extract enough $v_{spe}(t)$ from simulation data in fitting method. We suppose the average of these $v_{w}$ is the $v_{spe}$. Assuming that the waveform is the convolution of $v_{spe}$ and $q_{r}(t_{H})$ (or $n_{r}(t_{H})$), the Fast Fourier transform (fft) of $v_{w}$ and $v_{spe}$ are computed. A rectangular filter is added. Then compute the inverse fft of the quotient, which is between filtered fft of $v_{w}$ and fft of $v_{spe}$. 

\begin{itemize}
    \item Results = IFFT\{ Filter[ FFT($v_{w}$) ] / FFT($v_{spe}$) \}
\end{itemize}

The demonstration here shows a result with W-dist = 1.63ns. 

\begin{figure}[H]
    \centering
    \scalebox{0.4}{\input{figures/fftrans.pgf}}
    \caption{Fourier Deconvolution Demo, W-dist = 1.63}
\end{figure}

\subsection{Lucy deconvolution}
Lucy-Richardson deconvolution is a non linear iteration method, to calculate the deconvolution of signals. Lucy deconvolution has an advantage against Fourier deconvolution which is a constraint that $q_{r}(t_{H})$ or $n_{r}(t_{H})$ are larger than 0. 

In $t$-th Lucy iteration, the calculation shows in \eqref{eq:lucy-inter} where $v^{*}_{spe}$ is flipped $v_{spe}$. 
\begin{align}
    q_{r}^{(0)} &= \frac{v_{w}}{\int v_{spe}} \\
    q_{r}^{(n)} &= q_{r}^{(n-1)} \cdot \left(\frac{v_{w}}{q_{r}^{(n-1)} \otimes v_{spe}} \otimes v^{*}_{spe}\right) \label{eq:lucy-inter}
\end{align}

Usually 50 iterations were performed ($n_{max}=50$). The demonstration here shows a result with W-dist = 1.25ns. 

\begin{figure}[H]
    \centering
    \scalebox{0.4}{\input{figures/lucyddm.pgf}}
    \caption{Lucy Deconvolution Demo, W-dist = 1.25}
\end{figure}

\subsection{Fitting}
Waveform is the convolution of $v_{spe}$ and $q_{r}(t_{H})$ (or $n_{r}(t_{H})$), using $q_{r}(t_{H})$ as an example below (see formula~\eqref{eq:wave-con}). 
\begin{align}
    v_{w} &= q_{r} \otimes v_{spe} \label{eq:wave-con} \\
    L &= L(v_{r}(t), v_{w}(t)) = L(q_{r}(t_{H}), v_{spe}, v_{w}(t)) = RSS(v_{w}, q_{r} \otimes v_{spe}) \label{eq:loss-rss}
\end{align}

In fitting process, the parameter is $q_{r}(t_{H})$ or $n_{r}(t_{H})$ in each discrete $t_{H}$. The complete information hided in origin waveform is disturbed by background noise and pile-up. The loss (see formula~\ref{eq:loss-rss}) which is optimized is the Residual sum of squares (RSS) between the origin wave $v_{w}(t)$ and reconstructed wave $v_{r}(t)$ according to the parameters. The parameters will tend to be preciser when the reconstructed wave approaching to the origin wave. 

Fitting program is implemented with Limited-memory BFGS with bound constraint\cite{byrd_limited_1995} (L-BFGS-B). The $q_{r}$ and $n_{r}$ are constrained to be larger than 0. 

The L-BFGS-B depends on gradient evaluation and its iteration stops when gradient is smaller than a certain tiny value. In some circumstances the fitting result may stuck in local minimum rather than global minimum. An program based on Hamiltonian Monte Carlo (HMC) is developed intending to obtain global minimum. HMC is a efficient Markov Chain Monte Carlo (MCMC) method for achieving samples from a distribution for which direct sampling is difficult\cite{neal_mcmc_2012}. The sample derived by HMC can usually be ergodic in the distribution, so the global minimum will be obtain with large sampling set. But the results are similar with L-BFGS-B and HMC. 

The figure \ref{fig:fitting} shows one of the fitting result. We can see the origin waveform $v_{w}$ and reconstructed waveform $v_{r}$ are very similar. The reconstructed and truth $q_{r}$ are also similar. 
\begin{figure}[H]
    \centering
    \scalebox{0.4}{\input{figures/demoe1c4.pgf}}
    \caption{\label{fig:fitting} Fitting Demo, W-dist = 2.26}
\end{figure}

The overall result of W-dist shows in figure (see figure~\ref{fig:fitting-hist}\&\ref{fig:fitting-npos}). The error bar shows 10 to 90 percentile of Wasserstein distance distribution. 

\begin{minipage}{.5\textwidth}
\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/xiaopeipchargehist.pgf}}
    \caption{\label{fig:fitting-hist} $W_{d}$ Histogram when fitting $q_{r}$}
\end{figure}
\end{minipage}
\begin{minipage}{.5\textwidth}
\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/xiaopeipchargestats.pgf}}
    \caption{\label{fig:fitting-npos} $W_{d}$ vs $N_{pos}$ when fitting $q_{r}$}
\end{figure}
\end{minipage}

% \subsection{CNN}
\subsection{CNN}

\subsubsection{Network structure}
%\subsection{What is a good Network Structure?} 

Advances in neural networks have brought breakthroughs in various domains like Computer Vision and Natural Language Processing. As an efficient composition with weighted additions and pointwise nonlinearities, the method has prevailed against most of the traditional algorithms in pattern recognition tasks. In our experiment, we introduced a multi-layer convolutional neural network to process time-sensitive signals from detector outputs. Based on the Physics nature that a detector signal (PMT outputs) do only have a local correlation with recent incoming particles (photons incidents), we chose convolutional setups with a moderate total width coverage. From a view of information, a broader coverage by an output neuron's receptive field on its related area will contribute to higher accuracy, while redundant connections could only lead to excessive computation and lower processing speed. As a result, a wise setup should try to cover all relevant signal areas exclusively while cutting off every connection unnecessary, balancing the speed and accuracy from the two mentioned effects.

A similar trade-off also exists in the depth of the neural network. A deeper network could provide more complex combinations to all detected features, and the computation complexity of result calculation changes linearly with the depth. With the existence of advanced structure like residual connection and strategies like batch-norm, depth in training is never a problem. However, to cut the computation in massive experimental data, a network should be relatively shallow. Detector signals are relatively similar and peak-shaped. Such a simple pattern does not require many layers to recognize. A good design for the task is a network with 4 to 6 layers. Deeper structures may bring a slight improvement in precision but will introduce a considerable increase in processing cost.

A convolutional neural network is developed to analys the waveform. Here is the structure of CNN which has 5 convolutional layer (see figure~\ref{fig:struct}). The length of data remains the same. 

\subsubsection{Processing workflow}
%\subsection{What is a complete workflow of Data Processing?}
The complete workflow of data processing consists of two stages, data training and predicting. Data training is a task of supervised learning.  Based on paired data examples, the goal is to find an efficient mapping from detector waves to particle incidents with backpropagation methods. In the training process, a loss function judges the difference between training outputs and their referenced truth, and the training process is to minimize the loss. The product of network training is a function that creates desired outputs from inputs. By directly putting waveforms as inputs, one can get demanded outputs from a trained network in prediction.
%<Add a workflow description here>

\subsubsection{Loss function}
%\subsection{What is a good Loss Function?}
A critical issue matters the network training is the loss function. Particle incidence only happens in a small proportion of time channels within a recorded sequence, which means the outputs and related truth are always sparse. While operating with ineffective loss functions, training processes always ends up in local optimal of constant output due to the sparsity. Also, in practice, the form of loss function influence heavily on the final prediction performance. 

A well-designed loss function should meet two requirements as follows: it should handle the sparsity, and it should give a fair judgement to the output in training. A qualified loss function could work on either sequence values or normalized distributions. In pursuit of time precision, a good algorithm should encourage correct predictions in the close neighbourhoods of their corresponding truth, while punishing outputs that are incorrect or inaccurate in time. While working on the sequence outputs, such a mechanism is easy to implement but hard to arrange appropriately. It is hard to find a fair arrangement of punishment weight matching all circumstance. On the other hand, statistical distances and divergences could assess the difference in distribution but are hard to implement in a trainable form for backpropagation. 

To tackle the mentioned difficulties, efforts of our work have established feasible, robust solutions with guaranteed performance and convergence for each case of processing. We will describe the details of the method in the following section.

\emph{Value-based Reconstruction Loss}
% Introductory Photos should be added to this part.
To cope with sparsity in value-based processing, we have introduced a reconstruction procedure to build up a waveform based on its corresponding particle incidences. By introducing a reverse process after neural network computing, one could define the loss function on a denser wave domain instead of the original incidence domain. Expression of the reconstruction is arbitrary but should fit the paired relationship expressed by data samples. Typically, one should add a training process to fit the parameters in construction expressions before training the predicting neural networks.
%<Add an algorithm description here>

\emph{CDF Wasserstein Loss}
A direct implementation of judgement metrics into loss function is often difficult. To deal with sparsity and encourage time accuracy, we established the loss function on the cumulative distribution functions (CDF) of normalized outputs. The form of cumulative sums could build a connection between sequence prediction and its previous values, making optimization through history possible. Moreover, the first Wasserstein distance between two 1D distributions is equivalent to the norm-1 difference of two corresponding CDFs. The optimal transport amount described by this metric is a reliable measurement standard to all distribution differences, including cases in our application.

\begin{figure}[H]
\begin{minipage}{.3\textwidth}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.63\textwidth]{figures/model.png}
    \caption{\label{fig:struct} CNN Structure}
\end{figure}
\end{minipage}
\begin{minipage}{.7\textwidth}
\begin{figure}[H]
    \centering
    \resizebox{0.7\textwidth}{!}{\input{figures/epoch.pgf}}
    \caption{\label{fig:loss} Loss variation during training}
\end{figure}
\end{minipage}
\end{figure}

\subsubsection{Result}
In the training process, we trained CNN for each PMT channel. The loss which is Wasserstein distance during training show in figure \ref{fig:loss}. 

The result shows that CNN is the best for reconstruction of $q_{r}(t_{H})$ and $n_{r}(t_{H})$. The error bar shows 10 to 90 percentile of Wasserstein distance distribution. 

\begin{minipage}{.5\textwidth}
\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/xiaopeipchargehist.pgf}}
    \caption{$W_{d}$ Histogram when CNN $q_{r}$}
\end{figure}
\end{minipage}
\begin{minipage}{.5\textwidth}
\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/xiaopeipchargestats.pgf}}
    \caption{$W_{d}$ vs $N_{pos}$ when CNN $q_{r}$}
\end{figure}
\end{minipage}

% section Algorithm (end)