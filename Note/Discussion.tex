\section{Summary and Discussion} % (fold)
\label{sec:discussion}

\subsection{Program Efficiency}

The efficiency of 4 performant methods on our simulation dataset show in Table~\ref{fig:efficiency}. The CNN on GPU is faster than LucyDDM and FBMP, and much faster than gradient descent.  Number of iteration for LucyDDM and gradient descent and $t'_i$ sampling frequency of FBMP can be decreased to trade for speed.  The time consumed by FBMP contains the initialization time of LucyDDM pre-conditioner.

\begin{table}[H]
    \centering
    \caption{\label{fig:efficiency} Reconstruction Efficiency.}
    \begin{tabular}{cc}
        \hline
        & Performance/$10^{5}$Waveform \\
        \hline
        CNN & 15.7s (GPU\tablefootnote{one graphics card of NVIDIA\textsuperscript{\textregistered} A100.}) \\
        Gradient Descent & 754.1s (CPU\tablefootnote{100 CPU cores of AMD EYPC\texttrademark\ 7702}) \\
        LucyDDM & 845.9s (CPU) \\
        FBMP & 695.4s (CPU) \\
        \hline
    \end{tabular}
\end{table}

\subsection{Posterior Charge Distribution}

\begin{figure}[H]
    \centering
    \resizebox{0.6\textwidth}{!}{\input{figures/recchargehist.pgf}}
    \caption{\label{fig:recchargehist}  $\hat{q}$ distribution, $\mu=4, \tau=\SI{20}{ns}, \sigma=\SI{5}{ns}$}
\end{figure}

The charge of reconstruction, $\hat{q}$, result distribution when $\mu=4, \tau=20\mathrm{ns}, \sigma=10\mathrm{ns}$ shows in figure (see figure~\ref{fig:recchargehist}). 

The steep edge near 0 in these distributions results from the cut of the original $\hat{q}$, which is intended to remove fragment values of $\hat{q}$. But as we can see in figure~\ref{fig:recchargehist}, the charge distribution of LucyDDM, Fitting, and CNN are severely distorted, while the charge distribution of FBMP partly retains the shape of the original (or prior) distribution of charge and only some skewing persists. 

During optimization of Wasserstein distance between $\hat{q}(t)$ and $q_{tru}(t)$ (e.g. CNN) or RSS between the origin wave $v_{w}(t)$ and reconstructed wave $v_{r}(t)$ (e.g. Fitting and LucyDDM), the total number of hittime which is the degree of freedom (DOF) of parameters is a constant, and the analysis process is not treated as a sparse regression problem. So a lot of parameters in $q$ turn out to be fragment values, which distorts the $\hat{q}$ distribution. So the reduction of DOF before estimation of parameters in FBMP gives relatively good results in sparsity, though it is still noticeable that the slight skewness of charge distribution of FBMP persists. 

% Bayesian

As the origin waveform $v_{w}(t)$ is contaminated by Gaussian noise, the optimization a of single loss might be disturbed by the degeneracy of reconstruction results, which means for different $\hat{q}(t)$, the W-dist or RSS can result in the identity or very close. So it is adequate if we can obtain several samples from parameter space of $q$, and even superior if we can give the posterior probability of these samples. Additionally, the expansibility of the Bayesian method will allow us to retain sufficient information in subsequent steps such as event reconstruction. 

% Time bin

But as we see, the reconstruction results of hittime, $\hat{t}$, are discrete values (time bin edges in a DAQ window). To obtain continuous values of $\hat{t}$ may result in better analysis results. The results in the study show that when using refined time bins, the time resolution, the sparsity of reconstructed PEs, and all figures of merits (Wasserstein distance and RSS) are better, however, a lost efficiency. 

% Pedestal & Hardware

The evaluation of the pedestal of waveforms is not included in this work, which is a potential future work to do. Additionally, widely equipped PMTs bring the storage pressure of readout data. This problem can be solved by a voltage data pre-process hardware where waveform analysis is implemented, which is equivalent, or even more effective than data compression. 

\subsection{Timing Resolution}
\label{subsec:timeresolution}

% Likelihood

Formula \eqref{eq:pseudo} is the likelihood to estimate $t_{0}$ in formula \eqref{eq:time-pro} for methods except FBMP. But $q_{i}$ is the charge in each time bin $t_{i}$ rather the number of PE. For FBMP, formula \eqref{eq:bayesianinter} is the likelihood to estimate both $t_{0}$ and $\mu$. 

The timing resolution $\delta$ using waveform analysis results (charge $\hat{q}$) of these methods are computed and collected. The $t_{0}$ reconstruction process is also MLE, which introduced by the formula \eqref{eq:pseudo}. Additionally, FBMP provides dozens of samples of $q$, which allows us to derive MLE estimation of $t_{0}$. The comparison between timing resolution using the all PE, and the 4 methods is shown in figure~\ref{fig:deltamethods}. 

\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/vs-deltamethodsdiv.pgf}}
    \caption{\label{fig:deltamethods} Timing reconstruction ratio of resolution $\delta/\delta_{\mathrm{all}}$ of methods}
\end{figure}

In the figure, $\mathrm{FBMP}$ corresponds to the estimation of $t_{0}$ with all samples provided by FBMP. 

All 4 methods (LucyDDM, Fitting, CNN, FBMP) provide better timing resolution $\delta$ than only using the first PE during construction, comparing to figure~\ref{fig:reso-diff}. 

\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/vs-bias.pgf}}
    \caption{\label{fig:biasmethods}Timing reconstruction bias of methods}
\end{figure}

We can also see that in figure~\ref{fig:deltamethods}, the $t_0$ estimation bias of 4 methods are all similar to the bias of estimation based on all PE. The big bias on $\tau=\SI{20}{ns}, \sigma=\SI{5}{ns}$ datasets when $\mu$ is small is intrinsic. 

\subsection{Charge Reconstruction}
\label{subsec:chargereconstruction}

While methods except FBMP all include charge normalization where $\hat{q}_i$ are normalized to total charge by integration of the waveform $w(t)$, FBMP use \eqref{eq:fbmpcharge} to estimate charge directly. The normalization process will give the estimation of $\hat{\mu}=\int w(t)\mathrm{d}t$ which will be deteriorated by the randomization process such as charge distribution in \ref{subsec:spe}. 

Figure~\ref{fig:biasmu} shows the $\mu$ reconstruction of both integration and FBMP, where $\mathrm{FBMPmax}$ corresponds to $\mu$ reconstruction based on maximum posterior probability of $\hat{z}$ defined in \eqref{eq:zposterior}, and $\mathrm{FBMP}$ corresponds to $\mu$ reconstruction based on \textit{all} posterior $z'$. The bias of $\mu$ is smaller than $2.5\%$ for $\mathrm{FBMP}$. 

\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/vs-biasmu.pgf}}
    \caption{\label{fig:biasmu} FBMP charge reconstruction ratio of bias $\Delta\mu/\mu$ in different datasets}
\end{figure}

Considering the existing bias of $\mu$, the charge resolution is defined as the standard deviation of $\log{\hat{\mu}}$. Figure~\ref{fig:deltamu} shows the charge resolution of both integration and FBMP. When $\mu$ is small, FBMP shows convincing resolution as expected. 

\begin{figure}[H]
    \centering
    \resizebox{\textwidth}{!}{\input{figures/vs-deltamethodsdivmu.pgf}}
    \caption{\label{fig:deltamu} FBMP charge reconstruction ratio of resolution $\sigma/\sigma_{\log\mu}$ in different datasets}
\end{figure}

% section Discussion (end)
